{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Image_Recognition_CNN_Fine_Tuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8IJxdattBiYB0j3VyxI+V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjn14133/DNN/blob/main/DL_Image_Recognition_CNN_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz_6RMMvUHxT"
      },
      "source": [
        "# Image Recognition Models (trained):\n",
        "# VGG - Very standard design by University of Oxford\n",
        "# ResNet-50 - More complex design by Microsoft Research\n",
        "# Inception v3 - Even more complex design by Google\n",
        "# MobileNet - Low resource usage by Google\n",
        "# NASNet - Designed by algorithms by Google"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ugy2DGCTJyf"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from keras.applications import vgg16"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX6de9vRTjhF",
        "outputId": "86a36ebd-2152-40d3-bd65-e6a48722e5a3"
      },
      "source": [
        "# Load Keras' VGG 16 model that was pre-trained against the ImageNet database\n",
        "model = vgg16.VGG16()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n",
            "553476096/553467096 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5_J4y7jVwDI"
      },
      "source": [
        "# Load the image file, resizing it to 224*224 pixels (required by this model)\n",
        "img = image.load_img(\"bay.jpg\", target_size=(224, 224))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL2h0YKUWZ4x"
      },
      "source": [
        "# Convert the image to numpy array\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "# Add a fourth dimension (since Keras expects a list of images)\n",
        "x = np.expand_dims(x, axis=0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUaLfEeTWyRC",
        "outputId": "c18b6f3a-f783-43e6-c28d-d2366c279305"
      },
      "source": [
        "# Normalize the input image's pixel values to the range used when traning the neural network\n",
        "x = vgg16.preprocess_input(x)\n",
        "\n",
        "# Run the image through the deep neural network to make a prediction\n",
        "predictions = model.predict(x)\n",
        "\n",
        "# Look up the name of the predicted classes. Index zero is the results for the first image\n",
        "predicted_classes = vgg16.decode_predictions(predictions, top=9)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "49152/35363 [=========================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGHHhtumXxxU",
        "outputId": "db21e790-c025-4a9e-fe7c-a7e4e55fb42f"
      },
      "source": [
        "# Print out the results\n",
        "print(\"Top predictions for this image: \")\n",
        "\n",
        "for imagenet_id, name, likelihood in predicted_classes[0]:\n",
        "  print(\"Prediction: {} - {:2f}\".format(name, likelihood))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top predictions for this image: \n",
            "Prediction: seashore - 0.395213\n",
            "Prediction: promontory - 0.326128\n",
            "Prediction: lakeside - 0.119613\n",
            "Prediction: breakwater - 0.062801\n",
            "Prediction: sandbar - 0.045267\n",
            "Prediction: cliff - 0.011845\n",
            "Prediction: dock - 0.009196\n",
            "Prediction: boathouse - 0.003278\n",
            "Prediction: valley - 0.003194\n"
          ]
        }
      ]
    }
  ]
}