{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Images_Recognition_CNN_training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPIWHPNDpRs9wPpGNH0LdKy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjn14133/DNN/blob/main/DL_Images_Recognition_CNN_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQVi-Q7unN9i"
      },
      "source": [
        "# explore dataset: check for obvious errors\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz5VCyYPvVO3"
      },
      "source": [
        "# CIFAR-10 dataset - 32 by 32 pixels with 2 color channels images (60,000)\n",
        "from keras.datasets import cifar10"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IXJzQlBxyo_"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from pathlib import Path"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irmhklBlyCXU",
        "outputId": "eef3c20f-f14f-4ef8-dc01-b82085cc6d23"
      },
      "source": [
        "# Load data set\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt6Txa_myW3m"
      },
      "source": [
        "# Normalize data set to 0-to-1 range\n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM9UkS3Gz7mn"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qb6VwCry3CJ"
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q5tiB8a0fyR"
      },
      "source": [
        "# create a model and add layers \n",
        "model = Sequential()\n",
        "\n",
        "# Add 4 CONVOLUTIONAL LAYERS with input layer - 32 by 32 pixels with 2 color channels image\n",
        "# (filer number, window size, (padding for pixels on the edges), activation)\n",
        "# 2D for images, 1D for sound waves \n",
        "model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", input_shape=(32, 32, 3)))\n",
        "model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
        "# Add a MaxPooling layer to imporve the efficiency\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# Add a Dropout layer to throw away some data by cutting some connections between layers \n",
        "# 25% to 50%\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
        "# Add another MaxPooling layer to imporve the efficiency\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# Add another Dropout layer to throw away some data by cutting some connections between layers \n",
        "# 25% to 50%\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# create a Flatten layer to transition convolutional layers (2D) to dense layer (1D)\n",
        "model.add(Flatten())\n",
        "\n",
        "# create a Dense layer \n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "# Add another Dropout layer to throw away some data by cutting some connections between layers \n",
        "# 25% to 50%\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# create output layer - 10 different categories\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYIC85w16bix"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", \n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics = [\"accuracy\"])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNzKz8g_7EIU",
        "outputId": "8624e78c-14da-4e72-e0cf-0c691a8fbbc5"
      },
      "source": [
        "# Train the model\n",
        "# batch_size: (32, 128)\n",
        "# shuffle - randomize the order of the data\n",
        "# loss should go down while accuracy goes up\n",
        "model.fit(x_train, \n",
        "          y_train, \n",
        "          batch_size=32,\n",
        "          epochs = 30,\n",
        "          validation_data = (x_test, y_test),\n",
        "          shuffle = True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 217s 138ms/step - loss: 1.5192 - accuracy: 0.4407 - val_loss: 1.2280 - val_accuracy: 0.5668\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 216s 138ms/step - loss: 1.1412 - accuracy: 0.5949 - val_loss: 1.0032 - val_accuracy: 0.6415\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 215s 138ms/step - loss: 0.9794 - accuracy: 0.6548 - val_loss: 0.9497 - val_accuracy: 0.6626\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 216s 138ms/step - loss: 0.8840 - accuracy: 0.6916 - val_loss: 0.8886 - val_accuracy: 0.6919\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 215s 138ms/step - loss: 0.8180 - accuracy: 0.7117 - val_loss: 0.7432 - val_accuracy: 0.7440\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 215s 138ms/step - loss: 0.7667 - accuracy: 0.7304 - val_loss: 0.7259 - val_accuracy: 0.7421\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 213s 136ms/step - loss: 0.7293 - accuracy: 0.7454 - val_loss: 0.7129 - val_accuracy: 0.7523\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 213s 136ms/step - loss: 0.6925 - accuracy: 0.7565 - val_loss: 0.6921 - val_accuracy: 0.7628\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 214s 137ms/step - loss: 0.6683 - accuracy: 0.7661 - val_loss: 0.6978 - val_accuracy: 0.7646\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 213s 136ms/step - loss: 0.6401 - accuracy: 0.7774 - val_loss: 0.6996 - val_accuracy: 0.7618\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 215s 137ms/step - loss: 0.6230 - accuracy: 0.7821 - val_loss: 0.6950 - val_accuracy: 0.7631\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 215s 137ms/step - loss: 0.5950 - accuracy: 0.7910 - val_loss: 0.6743 - val_accuracy: 0.7689\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 212s 136ms/step - loss: 0.5833 - accuracy: 0.7945 - val_loss: 0.6851 - val_accuracy: 0.7684\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 215s 137ms/step - loss: 0.5708 - accuracy: 0.7981 - val_loss: 0.6495 - val_accuracy: 0.7852\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 216s 138ms/step - loss: 0.5497 - accuracy: 0.8075 - val_loss: 0.7134 - val_accuracy: 0.7612\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 0.5400 - accuracy: 0.8108 - val_loss: 0.6854 - val_accuracy: 0.7747\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 0.5246 - accuracy: 0.8170 - val_loss: 0.6634 - val_accuracy: 0.7793\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 0.5206 - accuracy: 0.8158 - val_loss: 0.6510 - val_accuracy: 0.7815\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 215s 138ms/step - loss: 0.5075 - accuracy: 0.8218 - val_loss: 0.6579 - val_accuracy: 0.7804\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 215s 138ms/step - loss: 0.4858 - accuracy: 0.8296 - val_loss: 0.6734 - val_accuracy: 0.7802\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 216s 138ms/step - loss: 0.4874 - accuracy: 0.8291 - val_loss: 0.7013 - val_accuracy: 0.7788\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 0.4802 - accuracy: 0.8313 - val_loss: 0.6674 - val_accuracy: 0.7840\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 0.4662 - accuracy: 0.8357 - val_loss: 0.6765 - val_accuracy: 0.7856\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 216s 138ms/step - loss: 0.4620 - accuracy: 0.8385 - val_loss: 0.6776 - val_accuracy: 0.7820\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 0.4585 - accuracy: 0.8402 - val_loss: 0.6557 - val_accuracy: 0.7898\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 0.4566 - accuracy: 0.8394 - val_loss: 0.6346 - val_accuracy: 0.7931\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 0.4511 - accuracy: 0.8418 - val_loss: 0.6549 - val_accuracy: 0.7937\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 218s 139ms/step - loss: 0.4381 - accuracy: 0.8454 - val_loss: 0.6891 - val_accuracy: 0.7780\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 0.4335 - accuracy: 0.8454 - val_loss: 0.6637 - val_accuracy: 0.7915\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 215s 138ms/step - loss: 0.4308 - accuracy: 0.8485 - val_loss: 0.6903 - val_accuracy: 0.7882\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efba0e0c750>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0_Af2Hg1tHc"
      },
      "source": [
        "# Save neural network structure\n",
        "model_structure = model.to_json()\n",
        "f = Path(\"CNN_model_structure.json\")\n",
        "f.write_text(model_structure)\n",
        "\n",
        "# Save neural network's trained weights\n",
        "model.save_weights(\"CNN_model_weights.h5\")\n"
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}